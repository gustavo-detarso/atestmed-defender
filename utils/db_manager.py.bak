#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import sqlite3
import pandas as pd
import inquirer
from datetime import datetime, timedelta

# ------------------------
# Helpers gerais
# ------------------------

def _ensure_db_dir():
    db_dir = './db'
    os.makedirs(db_dir, exist_ok=True)
    return os.path.join(db_dir, 'atestmed.db')

def _parse_hms(s: str):
    """
    Converte 'HH:MM:SS' em segundos (int). Retorna None se inválido.
    """
    if not s:
        return None
    try:
        parts = str(s).strip().split(':')
        if len(parts) != 3:
            return None
        h, m, sec = int(parts[0]), int(parts[1]), int(parts[2])
        return h * 3600 + m * 60 + sec
    except Exception:
        return None

def _diff_seconds(dt_ini: str, dt_fim: str):
    """
    Converte duas strings 'YYYY-MM-DD HH:MM:SS' em segundos (int).
    Se inválido, retorna None.
    """
    if not dt_ini or not dt_fim:
        return None
    try:
        t0 = datetime.strptime(dt_ini.strip(), "%Y-%m-%d %H:%M:%S")
        t1 = datetime.strptime(dt_fim.strip(), "%Y-%m-%d %H:%M:%S")
        return int((t1 - t0).total_seconds())
    except Exception:
        return None

def _to_int_flag(v, default=0):
    """
    Normaliza flags 0/1. Aceita '0','1', 0,1, True/False.
    """
    s = str(v).strip() if v is not None else ""
    if s in ("1", "True", "true"):
        return 1
    if s in ("0", "False", "false"):
        return 0
    return int(bool(default))

def _to_int_safe(x):
    try:
        s = str(x).strip()
        return int(s) if s != "" else None
    except Exception:
        return None

def _to_float_safe(x):
    try:
        s = str(x).replace(',', '.').strip()
        return float(s) if s != "" else None
    except Exception:
        return None

# ------------------------
# Coluna duracao_seg (cria e preenche)
# ------------------------

def ensure_duracao_seg_column(db_path: str):
    """
    Garante que a tabela analises tenha a coluna duracao_seg (em segundos),
    preenche a partir de (fim - ini) ou, no fallback, do string HH:MM:SS.
    Também faz um saneamento simples (negativos e >12h -> NULL).
    Idempotente.
    """
    if not os.path.exists(db_path):
        return

    conn = sqlite3.connect(db_path)
    cur = conn.cursor()

    # coluna existe?
    has_col = cur.execute("PRAGMA table_info(analises);").fetchall()
    has_duracao_seg = any(r[1] == "duracao_seg" for r in has_col)

    if not has_duracao_seg:
        print("➕ Adicionando coluna 'duracao_seg' em analises…")
        cur.execute("ALTER TABLE analises ADD COLUMN duracao_seg INTEGER;")
        conn.commit()
    else:
        print("ℹ️  Coluna 'duracao_seg' já existe (atualizando valores)…")

    # Preenche duracao_seg (preferência: diferença entre datas; fallback: HH:MM:SS)
    cur.executescript("""
    UPDATE analises
       SET duracao_seg =
           CASE
             WHEN dataHoraIniPericia IS NOT NULL AND dataHoraIniPericia <> ''
              AND dataHoraFimPericia IS NOT NULL AND dataHoraFimPericia <> ''
                THEN CAST(ROUND((julianday(dataHoraFimPericia) - julianday(dataHoraIniPericia)) * 86400.0) AS INTEGER)
             WHEN duracaoPericia GLOB '??:??:??'
                THEN (CAST(substr(duracaoPericia,1,2) AS INTEGER) * 3600)
                   + (CAST(substr(duracaoPericia,4,2) AS INTEGER) * 60)
                   +  CAST(substr(duracaoPericia,7,2) AS INTEGER)
             ELSE duracao_seg
           END
     WHERE duracao_seg IS NULL OR duracao_seg = '';
    """)

    # Saneamento: negativos e absurdos (> 12h) viram NULL
    cur.execute("""
        UPDATE analises
           SET duracao_seg = NULL
         WHERE duracao_seg IS NOT NULL
           AND (duracao_seg < 0 OR duracao_seg > 43200);
    """)
    conn.commit()

    total = cur.execute("SELECT COUNT(*) FROM analises;").fetchone()[0]
    nnull = cur.execute("SELECT COUNT(*) FROM analises WHERE duracao_seg IS NULL;").fetchone()[0]
    stats = cur.execute("""
        SELECT MIN(duracao_seg), ROUND(AVG(duracao_seg),1), MAX(duracao_seg)
          FROM analises WHERE duracao_seg IS NOT NULL;
    """).fetchone()

    conn.close()
    print("✅ 'duracao_seg' pronto.")
    print(f"   Linhas totais:          {total}")
    print(f"   Sem duracao_seg (NULL): {nnull}")
    print(f"   (min, avg, max) seg:    {stats}")

# ------------------------
# Funções de Acesso ao DB
# ------------------------

def create_database():
    """
    Cria/recria o SQLite com schema alinhado ao CSV:
    - motivoNaoConformado = flag 0/1
    - descrição do motivo em protocolos.motivo
    - CPFs como TEXT
    - inclui uf, cr, dr, uo, lotacao em protocolos (snapshot)
    - FK de protocolos.siapePerito -> peritos.siapePerito (NÃO por nome)
    - analises.duracao_seg INTEGER (segundos)
    """
    db_dir = './db'
    os.makedirs(db_dir, exist_ok=True)
    db_path = os.path.join(db_dir, 'atestmed.db')

    conn = sqlite3.connect(db_path)
    conn.execute("PRAGMA foreign_keys = ON;")
    cur = conn.cursor()

    cur.executescript("""
    PRAGMA foreign_keys = ON;

    DROP TABLE IF EXISTS indicadores;
    DROP TABLE IF EXISTS analises;
    DROP TABLE IF EXISTS protocolos;
    DROP TABLE IF EXISTS peritos;

    -- Dimensão de peritos
    CREATE TABLE peritos (
        siapePerito INTEGER PRIMARY KEY,
        nomePerito  TEXT NOT NULL,
        cpfPerito   TEXT,
        cr          TEXT,
        dr          TEXT
    );
    CREATE INDEX IF NOT EXISTS idx_peritos_nome ON peritos(nomePerito);

    -- Protocolos (snapshot + texto livre do motivo)
    -- AGORA com siapePerito e FK por siape
    CREATE TABLE protocolos (
        protocolo         INTEGER PRIMARY KEY,
        siapePerito       INTEGER NOT NULL,
        uf                TEXT,
        cr                TEXT,
        dr                TEXT,
        uo                TEXT,
        lotacao           TEXT,
        nomePerito        TEXT NOT NULL,     -- snapshot/auditoria (SEM FK)
        sigla             TEXT,
        tipoComunicacao   TEXT,
        dataComunicacao   TEXT,
        dataConclusao     TEXT,
        cpfCidadao        TEXT,
        tipoAfastamento   TEXT,
        motivo            TEXT,
        FOREIGN KEY (siapePerito) REFERENCES peritos (siapePerito)
    );
    CREATE INDEX IF NOT EXISTS idx_protocolos_perito_siape ON protocolos(siapePerito);
    CREATE INDEX IF NOT EXISTS idx_protocolos_perito_nome  ON protocolos(nomePerito);
    CREATE INDEX IF NOT EXISTS idx_protocolos_datas        ON protocolos(substr(dataComunicacao,1,10));

    -- Análises (fato)
    CREATE TABLE analises (
        protocolo              INTEGER PRIMARY KEY,
        siapePerito            INTEGER NOT NULL,
        cid10                  TEXT,
        conformado             INTEGER NOT NULL DEFAULT 1 CHECK (conformado IN (0,1)),
        motivoNaoConformado    INTEGER NOT NULL CHECK (motivoNaoConformado IN (0,1)),
        tipoPrazoAfastamento   TEXT,
        totalDiasRepouso       REAL,
        dataHoraIniPericia     TEXT NOT NULL,
        dataHoraFimPericia     TEXT,
        duracaoPericia         TEXT,
        duracao_seg            INTEGER,  -- ⏱️ segundos (calculado)
        FOREIGN KEY (protocolo)   REFERENCES protocolos (protocolo),
        FOREIGN KEY (siapePerito) REFERENCES peritos (siapePerito)
    );
    CREATE INDEX IF NOT EXISTS idx_analises_perito_data ON analises(siapePerito, substr(dataHoraIniPericia,1,10));
    CREATE INDEX IF NOT EXISTS idx_analises_nc          ON analises(motivoNaoConformado);

    -- Indicadores (placeholder)
    CREATE TABLE indicadores (
        perito     INTEGER PRIMARY KEY,
        icra       REAL,
        iatd       REAL,
        scoreFinal REAL,
        FOREIGN KEY (perito) REFERENCES peritos (siapePerito)
    );
    """)
    conn.commit()
    conn.close()
    print("✅ Banco de dados criado com sucesso!")

def load_csv_to_db(csv_path, db_path):
    """
    Carrega um CSV com as colunas:
    uf, cr, dr, uo, lotacao, nomePerito, protocolo, sigla, tipoComunicacao,
    dataComunicacao, dataConclusao, cpfCidadao, siapePerito, cpfPerito, cid10,
    conformado, motivoNaoConformado, tipoPrazoAfastamento, totalDiasRepouso,
    dataHoraIniPericia, dataHoraFimPericia, duracaoPericia, motivo, tipoAfastamento
    """
    # Leia tudo como string para não perder zeros (CPF)
    df = pd.read_csv(csv_path, dtype=str, keep_default_na=False)

    # Normaliza flags: se 'conformado' vier vazio, usa inverso de motivoNaoConformado
    df['motivoNaoConformado'] = df.get('motivoNaoConformado', '0').apply(lambda v: 1 if str(v).strip() == '1' else 0)
    if 'conformado' in df.columns:
        df['conformado'] = df['conformado'].apply(lambda v: 1 if str(v).strip() == '1' else 0)
    else:
        df['conformado'] = df['motivoNaoConformado'].apply(lambda nc: 0 if nc == 1 else 1)

    conn = sqlite3.connect(db_path)
    conn.execute("PRAGMA foreign_keys = ON;")
    cur = conn.cursor()

    for _, r in df.iterrows():
        siape = _to_int_safe(r.get('siapePerito'))
        nome  = (r.get('nomePerito') or '').strip() or None
        cpf_p = (r.get('cpfPerito') or '').strip() or None

        # peritos
        if siape and nome:
            cur.execute("""
                INSERT OR REPLACE INTO peritos (siapePerito, nomePerito, cpfPerito, cr, dr)
                VALUES (?, ?, ?, ?, ?)
            """, (siape, nome, cpf_p, r.get('cr') or None, r.get('dr') or None))

        # protocolos (snapshot do evento) — AGORA inclui siapePerito
        protocolo = _to_int_safe(r.get('protocolo'))
        if protocolo and siape:
            cur.execute("""
                INSERT OR REPLACE INTO protocolos (
                    protocolo, siapePerito, uf, cr, dr, uo, lotacao, nomePerito, sigla, tipoComunicacao,
                    dataComunicacao, dataConclusao, cpfCidadao, tipoAfastamento, motivo
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                protocolo,
                siape,                                # <-- vincula pelo SIAPE
                r.get('uf') or None,
                r.get('cr') or None,
                r.get('dr') or None,
                r.get('uo') or None,
                r.get('lotacao') or None,
                nome,
                r.get('sigla') or None,
                r.get('tipoComunicacao') or None,
                r.get('dataComunicacao') or None,
                r.get('dataConclusao') or None,
                (r.get('cpfCidadao') or '').strip() or None,
                r.get('tipoAfastamento') or None,
                (r.get('motivo') or '').strip() or None
            ))

        # analises (fato)
        if protocolo and siape and (r.get('dataHoraIniPericia') or '').strip():
            cur.execute("""
                INSERT OR REPLACE INTO analises (
                    protocolo, siapePerito, cid10, conformado, motivoNaoConformado,
                    tipoPrazoAfastamento, totalDiasRepouso, dataHoraIniPericia,
                    dataHoraFimPericia, duracaoPericia
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                protocolo,
                siape,
                (r.get('cid10') or '').strip() or None,
                int(r['conformado']),
                int(r['motivoNaoConformado']),
                (r.get('tipoPrazoAfastamento') or '').strip() or None,
                _to_float_safe(r.get('totalDiasRepouso')),
                r.get('dataHoraIniPericia') or None,
                r.get('dataHoraFimPericia') or None,
                r.get('duracaoPericia') or None
            ))

    conn.commit()
    conn.close()
    print(f"📥 Dados do arquivo '{os.path.basename(csv_path)}' carregados com sucesso!")

    # Garante/atualiza a coluna de duração em segundos após o load
    ensure_duracao_seg_column(db_path)

def calcular_indicadores(db_path):
    """
    Calcula ICRA, IATD e Score para cada perito com regras:
      - Excluir análises com duração > 1h (não entram em nada)
      - Contar análises <= 15s
      - Produtividade efetiva = total_analises / horas_efetivas (horas_efetivas = soma das durações válidas / 3600)
      - Média nacional de %NC = média (por perito) de (nc/total) considerando apenas peritos com total>0
      - Sobreposição: marca 1 se existir qualquer overlap (mesmo perito) em análises válidas (com início e fim)
      - ICRA (soma de pesos):
          Produtividade ≥ 50 análises/hora  → +3.0
          Sobreposição entre análises       → +2.5
          ≥ 10 análises com duração ≤ 15 s  → +2.0
          %NC ≥ 2 × média nacional          → +1.0
      - IATD = 1 - (%NC do perito)
      - Score Final = ICRA + %NC
    """
    # Garante a coluna (caso o banco seja antigo)
    ensure_duracao_seg_column(db_path)

    conn = sqlite3.connect(db_path)
    conn.execute("PRAGMA foreign_keys = ON;")

    # Puxa os dados necessários
    df = pd.read_sql_query("""
        SELECT
            a.protocolo,
            a.siapePerito,
            a.dataHoraIniPericia,
            a.dataHoraFimPericia,
            a.duracao_seg,
            a.motivoNaoConformado
        FROM analises a
    """, conn)

    if df.empty:
        print("⚠️ Nenhuma análise encontrada. Indicadores zerados.")
        conn.close()
        return

    # Flags de presença de datas para o cálculo de overlap
    df['has_start'] = df['dataHoraIniPericia'].notna() & (df['dataHoraIniPericia'].astype(str).str.strip() != "")
    df['has_end']   = df['dataHoraFimPericia'].notna() & (df['dataHoraFimPericia'].astype(str).str.strip() != "")

    # Filtra válidas: duracao_seg presente e <= 3600 s
    valid = df[(df['duracao_seg'].notna()) & (df['duracao_seg'] <= 3600)].copy()
    valid['duracao_seg'] = valid['duracao_seg'].astype(int)

    # Se nada válido, zera indicadores
    cur = conn.cursor()
    if valid.empty:
        cur.execute("DELETE FROM indicadores;")
        cur.execute("""
            INSERT OR IGNORE INTO indicadores(perito, icra, iatd, scoreFinal)
            SELECT siapePerito, 0, 1, 0 FROM peritos;
        """)
        conn.commit()
        conn.close()
        print("⚠️ Todas as análises têm duração > 1h ou inválida. Indicadores zerados.")
        return

    # Agregações por perito
    grp = valid.groupby('siapePerito', as_index=False).agg(
        total_analises=('protocolo', 'count'),
        sum_sec=('duracao_seg', 'sum'),
        count_15s=('duracao_seg', lambda s: (s <= 15).sum()),
        nc_count=('motivoNaoConformado', 'sum')
    )
    grp['horas_efetivas'] = grp['sum_sec'] / 3600.0
    grp['produtividade'] = grp.apply(
        lambda r: (r['total_analises'] / r['horas_efetivas']) if r['horas_efetivas'] > 0 else 0.0,
        axis=1
    )
    grp['pct_nc'] = grp.apply(
        lambda r: (r['nc_count'] / r['total_analises']) if r['total_analises'] > 0 else 0.0,
        axis=1
    )

    # Média nacional de %NC (média simples entre peritos com total>0)
    media_nc = grp['pct_nc'].mean() if not grp.empty else 0.0

    # Sobreposição por perito (usa ini/fim)
    overlap_map = {}
    DATE_FMT = "%Y-%m-%d %H:%M:%S"
    subset = valid[(valid['has_start']) & (valid['has_end'])] if {'has_start','has_end'}.issubset(valid.columns) else \
             df[(df['has_start']) & (df['has_end'])]

    for perito, g in subset.groupby('siapePerito'):
        try:
            tmp = g[['dataHoraIniPericia', 'dataHoraFimPericia']].copy()
            tmp['dataHoraIniPericia'] = tmp['dataHoraIniPericia'].astype(str).str.strip()
            tmp['dataHoraFimPericia'] = tmp['dataHoraFimPericia'].astype(str).str.strip()
            tmp['ini'] = pd.to_datetime(tmp['dataHoraIniPericia'], format=DATE_FMT, errors='coerce')
            tmp['fim'] = pd.to_datetime(tmp['dataHoraFimPericia'], format=DATE_FMT, errors='coerce')
            tmp = tmp.dropna(subset=['ini', 'fim']).sort_values('ini')

            has_overlap = False
            last_end = None
            for _, r in tmp.iterrows():
                if last_end is not None and r['ini'] < last_end:
                    has_overlap = True
                    break
                last_end = r['fim']
            overlap_map[perito] = 1 if has_overlap else 0
        except Exception:
            overlap_map[perito] = 0

    for perito in grp['siapePerito'].tolist():
        if perito not in overlap_map:
            overlap_map[perito] = 0
    grp['has_overlap'] = grp['siapePerito'].map(overlap_map).fillna(0).astype(int)

    # ICRA (pesos)
    def _icra_row(r):
        icra = 0.0
        if r['produtividade'] >= 50.0:
            icra += 3.0
        if r['has_overlap'] == 1:
            icra += 2.5
        if r['count_15s'] >= 10:
            icra += 2.0
        if (media_nc > 0) and (r['pct_nc'] >= 2.0 * media_nc):
            icra += 1.0
        return icra

    grp['icra'] = grp.apply(_icra_row, axis=1)
    grp['iatd'] = 1.0 - grp['pct_nc']
    grp['scoreFinal'] = grp['icra'] + grp['pct_nc']

    # Salva na tabela indicadores
    cur.execute("DELETE FROM indicadores;")
    cur.executemany("""
        INSERT OR REPLACE INTO indicadores (perito, icra, iatd, scoreFinal)
        VALUES (?, ?, ?, ?)
    """, list(zip(grp['siapePerito'], grp['icra'], grp['iatd'], grp['scoreFinal'])))
    conn.commit()
    conn.close()
    print("🔢 Indicadores (ICRA, IATD, Score) calculados/atualizados com sucesso.")

# ------------------------
# Fluxo Principal (CLI)
# ------------------------

def process_database():
    db_path = _ensure_db_dir()

    if not os.path.exists(db_path):
        q1 = [inquirer.List('opt', message="O banco não foi encontrado. Deseja criar?",
                             choices=['✅ Sim, criar', '❌ Não, sair'], carousel=True)]
        a1 = inquirer.prompt(q1)
        if a1 and a1['opt'].startswith('✅'):
            create_database()
            # Importar CSVs
            q2 = [inquirer.List('opt2', message="Carregar CSVs de 'data/raw'...",
                                  choices=['📂 Todos', '📄 Um a um'], carousel=True)]
            a2 = inquirer.prompt(q2)
            files = [f for f in os.listdir('./data/raw') if f.lower().endswith('.csv')]
            if a2 and a2['opt2'].startswith('📂'):
                for f in files:
                    load_csv_to_db(os.path.join('./data/raw', f), db_path)
            else:
                for f in files:
                    qf = [inquirer.Confirm('c', message=f"Carregar '{f}'?", default=True)]
                    af = inquirer.prompt(qf)
                    if af and af.get('c'):
                        load_csv_to_db(os.path.join('./data/raw', f), db_path)

            # garante coluna e calcula indicadores
            ensure_duracao_seg_column(db_path)
            calcular_indicadores(db_path)
        else:
            print("👋 Operação cancelada.")
            return
    else:
        q3 = [inquirer.List('opt3', message="Banco já existe. O que deseja fazer?",
                             choices=['🔄 Recriar', '♻️ Atualizar'], carousel=True)]
        a3 = inquirer.prompt(q3)
        if a3 and a3['opt3'].startswith('🔄'):
            qc = [inquirer.Confirm('c', message="Tem certeza que quer excluir e recriar?", default=False)]
            ac = inquirer.prompt(qc)
            if ac and ac.get('c'):
                os.remove(db_path)
                create_database()
                # Importar CSVs
                q4 = [inquirer.List('opt4', message="Carregar CSVs de 'data/raw'...",
                                     choices=['📂 Todos', '📄 Um a um'], carousel=True)]
                a4 = inquirer.prompt(q4)
                files = [f for f in os.listdir('./data/raw') if f.lower().endswith('.csv')]
                if a4 and a4['opt4'].startswith('📂'):
                    for f in files:
                        load_csv_to_db(os.path.join('./data/raw', f), db_path)
                else:
                    for f in files:
                        qf = [inquirer.Confirm('c', message=f"Carregar '{f}'?", default=True)]
                        af = inquirer.prompt(qf)
                        if af and af.get('c'):
                            load_csv_to_db(os.path.join('./data/raw', f), db_path)

                ensure_duracao_seg_column(db_path)
                calcular_indicadores(db_path)
            else:
                print("👋 Operação cancelada.")
                return
        else:
            q5 = [inquirer.List('opt5', message="Atualizar com dados novos: carregar CSVs?",
                                 choices=['📂 Todos', '📄 Um a um'], carousel=True)]
            a5 = inquirer.prompt(q5)
            files = [f for f in os.listdir('./data/raw') if f.lower().endswith('.csv')]
            if a5 and a5['opt5'].startswith('📂'):
                for f in files:
                    load_csv_to_db(os.path.join('./data/raw', f), db_path)
            else:
                for f in files:
                    qf = [inquirer.Confirm('c', message=f"Carregar '{f}'?", default=True)]
                    af = inquirer.prompt(qf)
                    if af and af.get('c'):
                        load_csv_to_db(os.path.join('./data/raw', f), db_path)

            ensure_duracao_seg_column(db_path)
            calcular_indicadores(db_path)

if __name__ == '__main__':
    process_database()

